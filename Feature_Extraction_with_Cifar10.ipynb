{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Nothing fancy here, just some imports I need to run the code, **pickle** is used to load the bottleneck features."
      ],
      "metadata": {
        "id": "1yrzXk5XGNgY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E0zbGQUdxc2D"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Activation, Flatten,Input\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I define some command line flags, this avoids having to manually open and edit the file if I want to change the files we train and validate our model with.\n",
        "\n",
        "I added a couple of command-line flags to set the number of epochs and batch size. This is more for convenience than anything else."
      ],
      "metadata": {
        "id": "pTfTEZsOIomY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flags = tf.app.flags\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "# command line flags\n",
        "flags.DEFINE_string('training_file', '', \"Bottleneck features training file (.p)\")\n",
        "flags.DEFINE_string('validation_file', '', \"Bottleneck features validation file (.p)\")\n",
        "flags.DEFINE_integer('epochs', 50, \"The number of epochs.\")\n",
        "flags.DEFINE_integer('batch_size', 256, \"The batch size.\")\n"
      ],
      "metadata": {
        "id": "SKykEcEwz01K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A utility function that loads the bottleneck features from the pickled training and validation files."
      ],
      "metadata": {
        "id": "gCsgchWOIlP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_bottleneck_data(training_file, validation_file):\n",
        "    \"\"\"\n",
        "    Utility function to load bottleneck features.\n",
        "\n",
        "    Arguments:\n",
        "        training_file - String\n",
        "        validation_file - String\n",
        "    \"\"\"\n",
        "    print(\"Training file\", training_file)\n",
        "    print(\"Validation file\", validation_file)\n",
        "\n",
        "    with open(training_file, 'rb') as f:\n",
        "        train_data = pickle.load(f)\n",
        "    with open(validation_file, 'rb') as f:\n",
        "        validation_data = pickle.load(f)\n",
        "\n",
        "    X_train = train_data['features']\n",
        "    y_train = train_data['labels']\n",
        "    X_val = validation_data['features']\n",
        "    y_val = validation_data['labels']\n",
        "\n",
        "    return X_train, y_train, X_val, y_val"
      ],
      "metadata": {
        "id": "-zUS0Pl4z3PP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where I defined ( a very simple model, a linear layer (Dense in Keras terms) followed by a softmax activation. The Adam optimizer is used ) and trained the model. Notice FLAGS.training_file and FLAGS.validation_file are passed into load_bottleneck_data. These refer to the command line flags defined earlier.\n",
        "\n",
        "Here I finded the number of classes for the dataset. **np.unique** returns all the unique elements of a numpy array. The elements of y_train are integers, 0-9 for Cifar10 and  So, when combined with len we get back the number of classes."
      ],
      "metadata": {
        "id": "lTBbIftPJmrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(_):\n",
        "\n",
        "    # load bottleneck data of VGG architecture \n",
        "\n",
        "    # training_file = \"vgg_cifar10_bottleneck_features_train.p\"\n",
        "    # validation_file = \"vgg_cifar10_bottleneck_features_validation.p\"\n",
        "    # X_train, y_train, X_val, y_val = load_bottleneck_data(training_file,validation_file)\n",
        "\n",
        "    # Using Flags\n",
        "    X_train, y_train, X_val, y_val = load_bottleneck_data(FLAGS.training_file, FLAGS.validation_file)\n",
        "\n",
        "    print(X_train.shape, y_train.shape)\n",
        "    print(X_val.shape, y_val.shape)\n",
        "\n",
        "    \n",
        "    n_classes = len(np.unique(y_train))\n",
        "\n",
        "    # define model\n",
        "    shape_in = X_train.shape[1:]\n",
        "    inputs = tf.keras.Input(shape=shape_in)\n",
        "    x = Flatten()(inputs)\n",
        "    outputs = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train The Model \n",
        "    # model.fit(X_train, y_train, epochs=50, batch_size=256 , validation_data=(X_val, y_val), shuffle=True)\n",
        "\n",
        "    # using Flags\n",
        "    model.fit(X_train, y_train, epochs=FLAGS.epochs, batch_size=FLAGS.batch_size, validation_data=(X_val, y_val), shuffle=True)\n"
      ],
      "metadata": {
        "id": "5Xyw8aSwz33I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c54e05-1ecf-4d31-9dcf-e8869ed6246e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training file vgg_cifar10_bottleneck_features_train.p\n",
            "Validation file vgg_cifar10_bottleneck_features_validation.p\n",
            "(40000, 1, 1, 512) (40000, 1)\n",
            "(10000, 1, 1, 512) (10000, 1)\n",
            "Epoch 1/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.3891 - accuracy: 0.5788 - val_loss: 0.7252 - val_accuracy: 0.7554\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.6357 - accuracy: 0.7849 - val_loss: 0.5551 - val_accuracy: 0.8104\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.5197 - accuracy: 0.8245 - val_loss: 0.4931 - val_accuracy: 0.8315\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.8402 - val_loss: 0.4641 - val_accuracy: 0.8396\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4342 - accuracy: 0.8503 - val_loss: 0.4417 - val_accuracy: 0.8482\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8577 - val_loss: 0.4310 - val_accuracy: 0.8549\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3969 - accuracy: 0.8636 - val_loss: 0.4227 - val_accuracy: 0.8548\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3856 - accuracy: 0.8672 - val_loss: 0.4169 - val_accuracy: 0.8575\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3778 - accuracy: 0.8703 - val_loss: 0.4191 - val_accuracy: 0.8570\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.3726 - accuracy: 0.8706 - val_loss: 0.4123 - val_accuracy: 0.8567\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3663 - accuracy: 0.8731 - val_loss: 0.4104 - val_accuracy: 0.8594\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3595 - accuracy: 0.8762 - val_loss: 0.4113 - val_accuracy: 0.8572\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.3556 - accuracy: 0.8758 - val_loss: 0.4126 - val_accuracy: 0.8601\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3551 - accuracy: 0.8758 - val_loss: 0.4149 - val_accuracy: 0.8558\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3513 - accuracy: 0.8767 - val_loss: 0.4149 - val_accuracy: 0.8568\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3477 - accuracy: 0.8776 - val_loss: 0.4125 - val_accuracy: 0.8586\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3457 - accuracy: 0.8788 - val_loss: 0.4095 - val_accuracy: 0.8615\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3439 - accuracy: 0.8796 - val_loss: 0.4129 - val_accuracy: 0.8578\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.8800 - val_loss: 0.4131 - val_accuracy: 0.8586\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3394 - accuracy: 0.8815 - val_loss: 0.4158 - val_accuracy: 0.8559\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3389 - accuracy: 0.8805 - val_loss: 0.4162 - val_accuracy: 0.8578\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3382 - accuracy: 0.8816 - val_loss: 0.4161 - val_accuracy: 0.8574\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3370 - accuracy: 0.8820 - val_loss: 0.4165 - val_accuracy: 0.8583\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3360 - accuracy: 0.8823 - val_loss: 0.4202 - val_accuracy: 0.8571\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3365 - accuracy: 0.8809 - val_loss: 0.4144 - val_accuracy: 0.8590\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3335 - accuracy: 0.8819 - val_loss: 0.4190 - val_accuracy: 0.8560\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.8815 - val_loss: 0.4239 - val_accuracy: 0.8577\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3323 - accuracy: 0.8825 - val_loss: 0.4271 - val_accuracy: 0.8572\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3331 - accuracy: 0.8834 - val_loss: 0.4244 - val_accuracy: 0.8535\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3320 - accuracy: 0.8823 - val_loss: 0.4296 - val_accuracy: 0.8546\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3326 - accuracy: 0.8827 - val_loss: 0.4259 - val_accuracy: 0.8581\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3313 - accuracy: 0.8831 - val_loss: 0.4342 - val_accuracy: 0.8561\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.8829 - val_loss: 0.4266 - val_accuracy: 0.8544\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3315 - accuracy: 0.8824 - val_loss: 0.4288 - val_accuracy: 0.8564\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3299 - accuracy: 0.8836 - val_loss: 0.4287 - val_accuracy: 0.8573\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3303 - accuracy: 0.8836 - val_loss: 0.4276 - val_accuracy: 0.8589\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3318 - accuracy: 0.8827 - val_loss: 0.4296 - val_accuracy: 0.8579\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3305 - accuracy: 0.8818 - val_loss: 0.4395 - val_accuracy: 0.8524\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3294 - accuracy: 0.8821 - val_loss: 0.4287 - val_accuracy: 0.8567\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3281 - accuracy: 0.8840 - val_loss: 0.4281 - val_accuracy: 0.8542\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3273 - accuracy: 0.8841 - val_loss: 0.4325 - val_accuracy: 0.8570\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3290 - accuracy: 0.8842 - val_loss: 0.4316 - val_accuracy: 0.8571\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3310 - accuracy: 0.8834 - val_loss: 0.4414 - val_accuracy: 0.8535\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3267 - accuracy: 0.8858 - val_loss: 0.4362 - val_accuracy: 0.8536\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3280 - accuracy: 0.8835 - val_loss: 0.4316 - val_accuracy: 0.8551\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3285 - accuracy: 0.8836 - val_loss: 0.4347 - val_accuracy: 0.8546\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3275 - accuracy: 0.8855 - val_loss: 0.4315 - val_accuracy: 0.8560\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3259 - accuracy: 0.8848 - val_loss: 0.4325 - val_accuracy: 0.8573\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.8853 - val_loss: 0.4460 - val_accuracy: 0.8552\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3268 - accuracy: 0.8840 - val_loss: 0.4360 - val_accuracy: 0.8568\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8d93358890>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parses flags and calls the `main` function above\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()\n"
      ],
      "metadata": {
        "id": "r3QZoEt1z59y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}